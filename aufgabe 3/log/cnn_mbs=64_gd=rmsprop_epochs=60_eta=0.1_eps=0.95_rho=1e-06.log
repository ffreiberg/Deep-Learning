Loading MNIST dataset...
Creating network...
Using rmsprop for updates with learning rate: 0.1, epsilon: 0.95, rho: 1e-06
Starting training...
Epoch 1 of 60 took 2.281s
  training loss:		0.063007
Epoch 2 of 60 took 2.205s
  training loss:		0.024454
Epoch 3 of 60 took 2.206s
  training loss:		0.017162
Epoch 4 of 60 took 2.206s
  training loss:		0.013700
Epoch 5 of 60 took 2.206s
  training loss:		0.011611
Epoch 6 of 60 took 2.206s
  training loss:		0.010116
Epoch 7 of 60 took 2.206s
  training loss:		0.009057
Epoch 8 of 60 took 2.206s
  training loss:		0.008244
Epoch 9 of 60 took 2.208s
  training loss:		0.007642
Epoch 10 of 60 took 2.212s
  training loss:		0.007140
Epoch 11 of 60 took 2.208s
  training loss:		0.006720
Epoch 12 of 60 took 2.208s
  training loss:		0.006399
Epoch 13 of 60 took 2.208s
  training loss:		0.006120
Epoch 14 of 60 took 2.208s
  training loss:		0.005859
Epoch 15 of 60 took 2.208s
  training loss:		0.005654
Epoch 16 of 60 took 2.208s
  training loss:		0.005464
Epoch 17 of 60 took 2.207s
  training loss:		0.005306
Epoch 18 of 60 took 2.207s
  training loss:		0.005134
Epoch 19 of 60 took 2.209s
  training loss:		0.005003
Epoch 20 of 60 took 2.215s
  training loss:		0.004859
Epoch 21 of 60 took 2.216s
  training loss:		0.004722
Epoch 22 of 60 took 2.217s
  training loss:		0.004626
Epoch 23 of 60 took 2.218s
  training loss:		0.004522
Epoch 24 of 60 took 2.216s
  training loss:		0.004413
Epoch 25 of 60 took 2.217s
  training loss:		0.004322
Epoch 26 of 60 took 2.216s
  training loss:		0.004212
Epoch 27 of 60 took 2.217s
  training loss:		0.004162
Epoch 28 of 60 took 2.216s
  training loss:		0.004073
Epoch 29 of 60 took 2.217s
  training loss:		0.003992
Epoch 30 of 60 took 2.215s
  training loss:		0.003917
Epoch 31 of 60 took 2.216s
  training loss:		0.003869
Epoch 32 of 60 took 2.216s
  training loss:		0.003799
Epoch 33 of 60 took 2.216s
  training loss:		0.003738
Epoch 34 of 60 took 2.217s
  training loss:		0.003680
Epoch 35 of 60 took 2.217s
  training loss:		0.003615
Epoch 36 of 60 took 2.215s
  training loss:		0.003577
Epoch 37 of 60 took 2.220s
  training loss:		0.003526
Epoch 38 of 60 took 2.218s
  training loss:		0.003475
Epoch 39 of 60 took 2.218s
  training loss:		0.003429
Epoch 40 of 60 took 2.217s
  training loss:		0.003376
Epoch 41 of 60 took 2.219s
  training loss:		0.003326
Epoch 42 of 60 took 2.218s
  training loss:		0.003296
Epoch 43 of 60 took 2.218s
  training loss:		0.003254
Epoch 44 of 60 took 2.218s
  training loss:		0.003211
Epoch 45 of 60 took 2.218s
  training loss:		0.003180
Epoch 46 of 60 took 2.218s
  training loss:		0.003131
Epoch 47 of 60 took 2.218s
  training loss:		0.003104
Epoch 48 of 60 took 2.218s
  training loss:		0.003051
Epoch 49 of 60 took 2.218s
  training loss:		0.003029
Epoch 50 of 60 took 2.218s
  training loss:		0.003004
Epoch 51 of 60 took 2.218s
  training loss:		0.002967
Epoch 52 of 60 took 2.218s
  training loss:		0.002936
Epoch 53 of 60 took 2.218s
  training loss:		0.002899
Epoch 54 of 60 took 2.218s
  training loss:		0.002867
Epoch 55 of 60 took 2.219s
  training loss:		0.002841
Epoch 56 of 60 took 2.218s
  training loss:		0.002840
Epoch 57 of 60 took 2.218s
  training loss:		0.002794
Epoch 58 of 60 took 2.217s
  training loss:		0.002779
Epoch 59 of 60 took 2.218s
  training loss:		0.002753
Epoch 60 of 60 took 2.218s
  training loss:		0.002719
Training accuracy:		98.76 %
Final results:
  test loss:			0.002955
  test accuracy:		98.78 %
