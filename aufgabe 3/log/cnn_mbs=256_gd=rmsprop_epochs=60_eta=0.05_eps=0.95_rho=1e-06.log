Loading MNIST dataset...
Creating network...
Using rmsprop for updates with learning rate: 0.05, epsilon: 0.95, rho: 1e-06
Starting training...
Epoch 1 of 60 took 2.006s
  training loss:		0.102783
Epoch 2 of 60 took 1.951s
  training loss:		0.085578
Epoch 3 of 60 took 1.951s
  training loss:		0.078417
Epoch 4 of 60 took 1.951s
  training loss:		0.066790
Epoch 5 of 60 took 1.952s
  training loss:		0.053412
Epoch 6 of 60 took 1.955s
  training loss:		0.043273
Epoch 7 of 60 took 1.952s
  training loss:		0.036272
Epoch 8 of 60 took 1.951s
  training loss:		0.031579
Epoch 9 of 60 took 1.953s
  training loss:		0.028376
Epoch 10 of 60 took 1.954s
  training loss:		0.026021
Epoch 11 of 60 took 1.957s
  training loss:		0.024219
Epoch 12 of 60 took 1.950s
  training loss:		0.022769
Epoch 13 of 60 took 1.952s
  training loss:		0.021575
Epoch 14 of 60 took 1.951s
  training loss:		0.020546
Epoch 15 of 60 took 1.951s
  training loss:		0.019677
Epoch 16 of 60 took 1.951s
  training loss:		0.018932
Epoch 17 of 60 took 1.952s
  training loss:		0.018245
Epoch 18 of 60 took 1.950s
  training loss:		0.017647
Epoch 19 of 60 took 1.952s
  training loss:		0.017105
Epoch 20 of 60 took 1.951s
  training loss:		0.016592
Epoch 21 of 60 took 1.954s
  training loss:		0.016133
Epoch 22 of 60 took 1.953s
  training loss:		0.015696
Epoch 23 of 60 took 1.955s
  training loss:		0.015292
Epoch 24 of 60 took 1.952s
  training loss:		0.014918
Epoch 25 of 60 took 1.951s
  training loss:		0.014557
Epoch 26 of 60 took 1.952s
  training loss:		0.014215
Epoch 27 of 60 took 1.950s
  training loss:		0.013909
Epoch 28 of 60 took 1.951s
  training loss:		0.013598
Epoch 29 of 60 took 1.953s
  training loss:		0.013313
Epoch 30 of 60 took 1.959s
  training loss:		0.013035
Epoch 31 of 60 took 1.961s
  training loss:		0.012776
Epoch 32 of 60 took 1.962s
  training loss:		0.012533
Epoch 33 of 60 took 1.965s
  training loss:		0.012289
Epoch 34 of 60 took 1.962s
  training loss:		0.012068
Epoch 35 of 60 took 1.962s
  training loss:		0.011846
Epoch 36 of 60 took 1.959s
  training loss:		0.011641
Epoch 37 of 60 took 1.961s
  training loss:		0.011443
Epoch 38 of 60 took 1.959s
  training loss:		0.011256
Epoch 39 of 60 took 1.961s
  training loss:		0.011064
Epoch 40 of 60 took 1.960s
  training loss:		0.010888
Epoch 41 of 60 took 1.960s
  training loss:		0.010713
Epoch 42 of 60 took 1.956s
  training loss:		0.010551
Epoch 43 of 60 took 1.961s
  training loss:		0.010398
Epoch 44 of 60 took 1.962s
  training loss:		0.010253
Epoch 45 of 60 took 1.960s
  training loss:		0.010116
Epoch 46 of 60 took 1.961s
  training loss:		0.009965
Epoch 47 of 60 took 1.962s
  training loss:		0.009826
Epoch 48 of 60 took 1.960s
  training loss:		0.009705
Epoch 49 of 60 took 1.960s
  training loss:		0.009576
Epoch 50 of 60 took 1.957s
  training loss:		0.009459
Epoch 51 of 60 took 1.958s
  training loss:		0.009342
Epoch 52 of 60 took 1.961s
  training loss:		0.009231
Epoch 53 of 60 took 1.962s
  training loss:		0.009119
Epoch 54 of 60 took 1.960s
  training loss:		0.009014
Epoch 55 of 60 took 1.963s
  training loss:		0.008913
Epoch 56 of 60 took 1.961s
  training loss:		0.008812
Epoch 57 of 60 took 1.959s
  training loss:		0.008720
Epoch 58 of 60 took 1.960s
  training loss:		0.008635
Epoch 59 of 60 took 1.960s
  training loss:		0.008535
Epoch 60 of 60 took 1.963s
  training loss:		0.008445
Training accuracy:		96.03 %
Final results:
  test loss:			0.007658
  test accuracy:		96.61 %
