Loading MNIST dataset...
Creating network...
Using rmsprop for updates with learning rate: 0.1, epsilon: 0.95, rho: 1e-06
Starting training...
Epoch 1 of 60 took 2.667s
  training loss:		0.044658
Epoch 2 of 60 took 2.614s
  training loss:		0.015492
Epoch 3 of 60 took 2.614s
  training loss:		0.011208
Epoch 4 of 60 took 2.614s
  training loss:		0.009118
Epoch 5 of 60 took 2.617s
  training loss:		0.007861
Epoch 6 of 60 took 2.618s
  training loss:		0.007012
Epoch 7 of 60 took 2.617s
  training loss:		0.006398
Epoch 8 of 60 took 2.618s
  training loss:		0.005906
Epoch 9 of 60 took 2.619s
  training loss:		0.005556
Epoch 10 of 60 took 2.617s
  training loss:		0.005232
Epoch 11 of 60 took 2.617s
  training loss:		0.004988
Epoch 12 of 60 took 2.617s
  training loss:		0.004756
Epoch 13 of 60 took 2.621s
  training loss:		0.004528
Epoch 14 of 60 took 2.617s
  training loss:		0.004370
Epoch 15 of 60 took 2.618s
  training loss:		0.004235
Epoch 16 of 60 took 2.617s
  training loss:		0.004084
Epoch 17 of 60 took 2.618s
  training loss:		0.003967
Epoch 18 of 60 took 2.618s
  training loss:		0.003850
Epoch 19 of 60 took 2.616s
  training loss:		0.003732
Epoch 20 of 60 took 2.617s
  training loss:		0.003635
Epoch 21 of 60 took 2.618s
  training loss:		0.003560
Epoch 22 of 60 took 2.617s
  training loss:		0.003455
Epoch 23 of 60 took 2.617s
  training loss:		0.003386
Epoch 24 of 60 took 2.616s
  training loss:		0.003285
Epoch 25 of 60 took 2.617s
  training loss:		0.003217
Epoch 26 of 60 took 2.618s
  training loss:		0.003148
Epoch 27 of 60 took 2.616s
  training loss:		0.003107
Epoch 28 of 60 took 2.617s
  training loss:		0.003036
Epoch 29 of 60 took 2.617s
  training loss:		0.002974
Epoch 30 of 60 took 2.617s
  training loss:		0.002924
Epoch 31 of 60 took 2.617s
  training loss:		0.002852
Epoch 32 of 60 took 2.617s
  training loss:		0.002821
Epoch 33 of 60 took 2.616s
  training loss:		0.002760
Epoch 34 of 60 took 2.617s
  training loss:		0.002715
Epoch 35 of 60 took 2.617s
  training loss:		0.002671
Epoch 36 of 60 took 2.620s
  training loss:		0.002648
Epoch 37 of 60 took 2.616s
  training loss:		0.002590
Epoch 38 of 60 took 2.615s
  training loss:		0.002551
Epoch 39 of 60 took 2.619s
  training loss:		0.002501
Epoch 40 of 60 took 2.634s
  training loss:		0.002465
Epoch 41 of 60 took 2.635s
  training loss:		0.002432
Epoch 42 of 60 took 2.634s
  training loss:		0.002399
Epoch 43 of 60 took 2.634s
  training loss:		0.002366
Epoch 44 of 60 took 2.634s
  training loss:		0.002340
Epoch 45 of 60 took 2.634s
  training loss:		0.002304
Epoch 46 of 60 took 2.634s
  training loss:		0.002270
Epoch 47 of 60 took 2.635s
  training loss:		0.002232
Epoch 48 of 60 took 2.634s
  training loss:		0.002203
Epoch 49 of 60 took 2.635s
  training loss:		0.002184
Epoch 50 of 60 took 2.634s
  training loss:		0.002166
Epoch 51 of 60 took 2.635s
  training loss:		0.002127
Epoch 52 of 60 took 2.635s
  training loss:		0.002107
Epoch 53 of 60 took 2.635s
  training loss:		0.002072
Epoch 54 of 60 took 2.635s
  training loss:		0.002058
Epoch 55 of 60 took 2.634s
  training loss:		0.002015
Epoch 56 of 60 took 2.635s
  training loss:		0.002009
Epoch 57 of 60 took 2.634s
  training loss:		0.001988
Epoch 58 of 60 took 2.635s
  training loss:		0.001966
Epoch 59 of 60 took 2.639s
  training loss:		0.001940
Epoch 60 of 60 took 2.634s
  training loss:		0.001912
Training accuracy:		99.13 %
Final results:
  test loss:			0.002330
  test accuracy:		98.94 %
