Loading MNIST dataset...
Creating network...
Using rmsprop for updates with learning rate: 0.05, epsilon: 0.95, rho: 1e-06
Starting training...
Epoch 1 of 60 took 2.671s
  training loss:		0.066803
Epoch 2 of 60 took 2.611s
  training loss:		0.024553
Epoch 3 of 60 took 2.609s
  training loss:		0.016793
Epoch 4 of 60 took 2.609s
  training loss:		0.013438
Epoch 5 of 60 took 2.608s
  training loss:		0.011505
Epoch 6 of 60 took 2.609s
  training loss:		0.010180
Epoch 7 of 60 took 2.610s
  training loss:		0.009255
Epoch 8 of 60 took 2.619s
  training loss:		0.008530
Epoch 9 of 60 took 2.619s
  training loss:		0.007942
Epoch 10 of 60 took 2.622s
  training loss:		0.007468
Epoch 11 of 60 took 2.619s
  training loss:		0.007065
Epoch 12 of 60 took 2.619s
  training loss:		0.006705
Epoch 13 of 60 took 2.618s
  training loss:		0.006412
Epoch 14 of 60 took 2.619s
  training loss:		0.006160
Epoch 15 of 60 took 2.619s
  training loss:		0.005930
Epoch 16 of 60 took 2.620s
  training loss:		0.005737
Epoch 17 of 60 took 2.619s
  training loss:		0.005531
Epoch 18 of 60 took 2.618s
  training loss:		0.005379
Epoch 19 of 60 took 2.619s
  training loss:		0.005227
Epoch 20 of 60 took 2.619s
  training loss:		0.005096
Epoch 21 of 60 took 2.619s
  training loss:		0.004957
Epoch 22 of 60 took 2.619s
  training loss:		0.004844
Epoch 23 of 60 took 2.618s
  training loss:		0.004724
Epoch 24 of 60 took 2.618s
  training loss:		0.004633
Epoch 25 of 60 took 2.623s
  training loss:		0.004536
Epoch 26 of 60 took 2.621s
  training loss:		0.004454
Epoch 27 of 60 took 2.621s
  training loss:		0.004366
Epoch 28 of 60 took 2.621s
  training loss:		0.004283
Epoch 29 of 60 took 2.621s
  training loss:		0.004203
Epoch 30 of 60 took 2.621s
  training loss:		0.004135
Epoch 31 of 60 took 2.621s
  training loss:		0.004073
Epoch 32 of 60 took 2.620s
  training loss:		0.003999
Epoch 33 of 60 took 2.625s
  training loss:		0.003938
Epoch 34 of 60 took 2.620s
  training loss:		0.003871
Epoch 35 of 60 took 2.620s
  training loss:		0.003821
Epoch 36 of 60 took 2.620s
  training loss:		0.003763
Epoch 37 of 60 took 2.621s
  training loss:		0.003705
Epoch 38 of 60 took 2.620s
  training loss:		0.003649
Epoch 39 of 60 took 2.621s
  training loss:		0.003618
Epoch 40 of 60 took 2.621s
  training loss:		0.003563
Epoch 41 of 60 took 2.621s
  training loss:		0.003520
Epoch 42 of 60 took 2.621s
  training loss:		0.003481
Epoch 43 of 60 took 2.620s
  training loss:		0.003427
Epoch 44 of 60 took 2.621s
  training loss:		0.003394
Epoch 45 of 60 took 2.622s
  training loss:		0.003357
Epoch 46 of 60 took 2.621s
  training loss:		0.003297
Epoch 47 of 60 took 2.622s
  training loss:		0.003273
Epoch 48 of 60 took 2.621s
  training loss:		0.003240
Epoch 49 of 60 took 2.621s
  training loss:		0.003202
Epoch 50 of 60 took 2.621s
  training loss:		0.003168
Epoch 51 of 60 took 2.621s
  training loss:		0.003122
Epoch 52 of 60 took 2.621s
  training loss:		0.003093
Epoch 53 of 60 took 2.621s
  training loss:		0.003058
Epoch 54 of 60 took 2.621s
  training loss:		0.003027
Epoch 55 of 60 took 2.621s
  training loss:		0.002991
Epoch 56 of 60 took 2.624s
  training loss:		0.002966
Epoch 57 of 60 took 2.620s
  training loss:		0.002938
Epoch 58 of 60 took 2.621s
  training loss:		0.002901
Epoch 59 of 60 took 2.620s
  training loss:		0.002884
Epoch 60 of 60 took 2.620s
  training loss:		0.002852
Training accuracy:		98.71 %
Final results:
  test loss:			0.003035
  test accuracy:		98.69 %
