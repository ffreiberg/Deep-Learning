Loading MNIST dataset...
Creating network...
Using rmsprop for updates with learning rate: 0.05, epsilon: 0.95, rho: 1e-06
Starting training...
Epoch 1 of 60 took 1.956s
  training loss:		0.114677
Epoch 2 of 60 took 1.916s
  training loss:		0.088048
Epoch 3 of 60 took 1.917s
  training loss:		0.085474
Epoch 4 of 60 took 1.917s
  training loss:		0.081818
Epoch 5 of 60 took 1.918s
  training loss:		0.076768
Epoch 6 of 60 took 1.918s
  training loss:		0.070312
Epoch 7 of 60 took 1.918s
  training loss:		0.062679
Epoch 8 of 60 took 1.917s
  training loss:		0.055046
Epoch 9 of 60 took 1.920s
  training loss:		0.048562
Epoch 10 of 60 took 1.918s
  training loss:		0.043436
Epoch 11 of 60 took 1.920s
  training loss:		0.039383
Epoch 12 of 60 took 1.918s
  training loss:		0.036172
Epoch 13 of 60 took 1.919s
  training loss:		0.033586
Epoch 14 of 60 took 1.919s
  training loss:		0.031483
Epoch 15 of 60 took 1.919s
  training loss:		0.029739
Epoch 16 of 60 took 1.918s
  training loss:		0.028259
Epoch 17 of 60 took 1.920s
  training loss:		0.026995
Epoch 18 of 60 took 1.917s
  training loss:		0.025916
Epoch 19 of 60 took 1.919s
  training loss:		0.024941
Epoch 20 of 60 took 1.917s
  training loss:		0.024087
Epoch 21 of 60 took 1.919s
  training loss:		0.023320
Epoch 22 of 60 took 1.917s
  training loss:		0.022625
Epoch 23 of 60 took 1.918s
  training loss:		0.021981
Epoch 24 of 60 took 1.925s
  training loss:		0.021380
Epoch 25 of 60 took 1.924s
  training loss:		0.020841
Epoch 26 of 60 took 1.920s
  training loss:		0.020340
Epoch 27 of 60 took 1.923s
  training loss:		0.019867
Epoch 28 of 60 took 1.921s
  training loss:		0.019428
Epoch 29 of 60 took 1.924s
  training loss:		0.019016
Epoch 30 of 60 took 1.923s
  training loss:		0.018626
Epoch 31 of 60 took 1.930s
  training loss:		0.018248
Epoch 32 of 60 took 1.928s
  training loss:		0.017907
Epoch 33 of 60 took 1.929s
  training loss:		0.017570
Epoch 34 of 60 took 1.931s
  training loss:		0.017255
Epoch 35 of 60 took 1.928s
  training loss:		0.016969
Epoch 36 of 60 took 1.931s
  training loss:		0.016676
Epoch 37 of 60 took 1.927s
  training loss:		0.016406
Epoch 38 of 60 took 1.929s
  training loss:		0.016153
Epoch 39 of 60 took 1.931s
  training loss:		0.015910
Epoch 40 of 60 took 1.929s
  training loss:		0.015678
Epoch 41 of 60 took 1.929s
  training loss:		0.015446
Epoch 42 of 60 took 1.929s
  training loss:		0.015231
Epoch 43 of 60 took 1.928s
  training loss:		0.015023
Epoch 44 of 60 took 1.930s
  training loss:		0.014841
Epoch 45 of 60 took 1.931s
  training loss:		0.014639
Epoch 46 of 60 took 1.928s
  training loss:		0.014451
Epoch 47 of 60 took 1.928s
  training loss:		0.014273
Epoch 48 of 60 took 1.932s
  training loss:		0.014089
Epoch 49 of 60 took 1.928s
  training loss:		0.013939
Epoch 50 of 60 took 1.928s
  training loss:		0.013779
Epoch 51 of 60 took 1.931s
  training loss:		0.013614
Epoch 52 of 60 took 1.927s
  training loss:		0.013474
Epoch 53 of 60 took 1.927s
  training loss:		0.013320
Epoch 54 of 60 took 1.929s
  training loss:		0.013174
Epoch 55 of 60 took 1.929s
  training loss:		0.013041
Epoch 56 of 60 took 1.934s
  training loss:		0.012897
Epoch 57 of 60 took 1.926s
  training loss:		0.012776
Epoch 58 of 60 took 1.929s
  training loss:		0.012647
Epoch 59 of 60 took 1.929s
  training loss:		0.012526
Epoch 60 of 60 took 1.930s
  training loss:		0.012404
Training accuracy:		93.89 %
Final results:
  test loss:			0.011288
  test accuracy:		94.57 %
