Loading MNIST dataset...
Creating network...
Using rmsprop for updates with learning rate: 0.5, epsilon: 0.95, rho: 1e-06
Starting training...
Epoch 1 of 60 took 2.673s
  training loss:		0.020644
Epoch 2 of 60 took 2.620s
  training loss:		0.006787
Epoch 3 of 60 took 2.620s
  training loss:		0.005268
Epoch 4 of 60 took 2.620s
  training loss:		0.004476
Epoch 5 of 60 took 2.620s
  training loss:		0.003972
Epoch 6 of 60 took 2.622s
  training loss:		0.003596
Epoch 7 of 60 took 2.619s
  training loss:		0.003302
Epoch 8 of 60 took 2.617s
  training loss:		0.003087
Epoch 9 of 60 took 2.617s
  training loss:		0.002884
Epoch 10 of 60 took 2.617s
  training loss:		0.002706
Epoch 11 of 60 took 2.617s
  training loss:		0.002550
Epoch 12 of 60 took 2.617s
  training loss:		0.002410
Epoch 13 of 60 took 2.617s
  training loss:		0.002314
Epoch 14 of 60 took 2.617s
  training loss:		0.002182
Epoch 15 of 60 took 2.615s
  training loss:		0.002087
Epoch 16 of 60 took 2.617s
  training loss:		0.002036
Epoch 17 of 60 took 2.617s
  training loss:		0.001939
Epoch 18 of 60 took 2.616s
  training loss:		0.001867
Epoch 19 of 60 took 2.617s
  training loss:		0.001792
Epoch 20 of 60 took 2.620s
  training loss:		0.001717
Epoch 21 of 60 took 2.616s
  training loss:		0.001642
Epoch 22 of 60 took 2.617s
  training loss:		0.001580
Epoch 23 of 60 took 2.617s
  training loss:		0.001529
Epoch 24 of 60 took 2.617s
  training loss:		0.001469
Epoch 25 of 60 took 2.617s
  training loss:		0.001421
Epoch 26 of 60 took 2.617s
  training loss:		0.001394
Epoch 27 of 60 took 2.616s
  training loss:		0.001350
Epoch 28 of 60 took 2.617s
  training loss:		0.001288
Epoch 29 of 60 took 2.616s
  training loss:		0.001249
Epoch 30 of 60 took 2.616s
  training loss:		0.001215
Epoch 31 of 60 took 2.616s
  training loss:		0.001164
Epoch 32 of 60 took 2.616s
  training loss:		0.001141
Epoch 33 of 60 took 2.616s
  training loss:		0.001113
Epoch 34 of 60 took 2.616s
  training loss:		0.001091
Epoch 35 of 60 took 2.615s
  training loss:		0.001042
Epoch 36 of 60 took 2.616s
  training loss:		0.001037
Epoch 37 of 60 took 2.617s
  training loss:		0.001000
Epoch 38 of 60 took 2.617s
  training loss:		0.000963
Epoch 39 of 60 took 2.617s
  training loss:		0.000949
Epoch 40 of 60 took 2.616s
  training loss:		0.000906
Epoch 41 of 60 took 2.616s
  training loss:		0.000891
Epoch 42 of 60 took 2.616s
  training loss:		0.000843
Epoch 43 of 60 took 2.620s
  training loss:		0.000854
Epoch 44 of 60 took 2.616s
  training loss:		0.000820
Epoch 45 of 60 took 2.616s
  training loss:		0.000807
Epoch 46 of 60 took 2.616s
  training loss:		0.000780
Epoch 47 of 60 took 2.617s
  training loss:		0.000762
Epoch 48 of 60 took 2.617s
  training loss:		0.000744
Epoch 49 of 60 took 2.616s
  training loss:		0.000713
Epoch 50 of 60 took 2.616s
  training loss:		0.000720
Epoch 51 of 60 took 2.616s
  training loss:		0.000686
Epoch 52 of 60 took 2.615s
  training loss:		0.000683
Epoch 53 of 60 took 2.616s
  training loss:		0.000669
Epoch 54 of 60 took 2.616s
  training loss:		0.000657
Epoch 55 of 60 took 2.616s
  training loss:		0.000626
Epoch 56 of 60 took 2.616s
  training loss:		0.000612
Epoch 57 of 60 took 2.615s
  training loss:		0.000602
Epoch 58 of 60 took 2.616s
  training loss:		0.000591
Epoch 59 of 60 took 2.616s
  training loss:		0.000562
Epoch 60 of 60 took 2.615s
  training loss:		0.000579
Training accuracy:		99.68 %
Final results:
  test loss:			0.001968
  test accuracy:		99.16 %
