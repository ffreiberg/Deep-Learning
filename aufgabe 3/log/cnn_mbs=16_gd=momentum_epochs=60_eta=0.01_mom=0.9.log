Loading MNIST dataset...
Creating network...
Using momentum for updates with learning rate: 0.01, momentum: 0.9
Starting training...
Epoch 1 of 60 took 3.702s
  training loss:		0.030275
Epoch 2 of 60 took 3.645s
  training loss:		0.010165
Epoch 3 of 60 took 3.651s
  training loss:		0.007568
Epoch 4 of 60 took 3.637s
  training loss:		0.006336
Epoch 5 of 60 took 3.640s
  training loss:		0.005527
Epoch 6 of 60 took 3.639s
  training loss:		0.005022
Epoch 7 of 60 took 3.651s
  training loss:		0.004605
Epoch 8 of 60 took 3.633s
  training loss:		0.004285
Epoch 9 of 60 took 3.632s
  training loss:		0.004044
Epoch 10 of 60 took 3.636s
  training loss:		0.003806
Epoch 11 of 60 took 3.635s
  training loss:		0.003611
Epoch 12 of 60 took 3.634s
  training loss:		0.003454
Epoch 13 of 60 took 3.638s
  training loss:		0.003330
Epoch 14 of 60 took 3.635s
  training loss:		0.003208
Epoch 15 of 60 took 3.639s
  training loss:		0.003064
Epoch 16 of 60 took 3.633s
  training loss:		0.002977
Epoch 17 of 60 took 3.639s
  training loss:		0.002863
Epoch 18 of 60 took 3.635s
  training loss:		0.002804
Epoch 19 of 60 took 3.638s
  training loss:		0.002739
Epoch 20 of 60 took 3.637s
  training loss:		0.002651
Epoch 21 of 60 took 3.628s
  training loss:		0.002566
Epoch 22 of 60 took 3.633s
  training loss:		0.002511
Epoch 23 of 60 took 3.642s
  training loss:		0.002443
Epoch 24 of 60 took 3.637s
  training loss:		0.002385
Epoch 25 of 60 took 3.640s
  training loss:		0.002327
Epoch 26 of 60 took 3.640s
  training loss:		0.002277
Epoch 27 of 60 took 3.633s
  training loss:		0.002226
Epoch 28 of 60 took 3.635s
  training loss:		0.002168
Epoch 29 of 60 took 3.637s
  training loss:		0.002114
Epoch 30 of 60 took 3.640s
  training loss:		0.002094
Epoch 31 of 60 took 3.634s
  training loss:		0.002034
Epoch 32 of 60 took 3.637s
  training loss:		0.002004
Epoch 33 of 60 took 3.640s
  training loss:		0.001959
Epoch 34 of 60 took 3.639s
  training loss:		0.001926
Epoch 35 of 60 took 3.637s
  training loss:		0.001889
Epoch 36 of 60 took 3.638s
  training loss:		0.001870
Epoch 37 of 60 took 3.631s
  training loss:		0.001833
Epoch 38 of 60 took 3.631s
  training loss:		0.001812
Epoch 39 of 60 took 3.640s
  training loss:		0.001744
Epoch 40 of 60 took 3.635s
  training loss:		0.001734
Epoch 41 of 60 took 3.639s
  training loss:		0.001701
Epoch 42 of 60 took 3.639s
  training loss:		0.001698
Epoch 43 of 60 took 3.636s
  training loss:		0.001656
Epoch 44 of 60 took 3.631s
  training loss:		0.001638
Epoch 45 of 60 took 3.639s
  training loss:		0.001610
Epoch 46 of 60 took 3.640s
  training loss:		0.001588
Epoch 47 of 60 took 3.636s
  training loss:		0.001537
Epoch 48 of 60 took 3.638s
  training loss:		0.001514
Epoch 49 of 60 took 3.638s
  training loss:		0.001500
Epoch 50 of 60 took 3.632s
  training loss:		0.001467
Epoch 51 of 60 took 3.636s
  training loss:		0.001461
Epoch 52 of 60 took 3.640s
  training loss:		0.001437
Epoch 53 of 60 took 3.636s
  training loss:		0.001412
Epoch 54 of 60 took 3.640s
  training loss:		0.001398
Epoch 55 of 60 took 3.635s
  training loss:		0.001380
Epoch 56 of 60 took 3.641s
  training loss:		0.001332
Epoch 57 of 60 took 3.634s
  training loss:		0.001331
Epoch 58 of 60 took 3.635s
  training loss:		0.001305
Epoch 59 of 60 took 3.642s
  training loss:		0.001286
Epoch 60 of 60 took 3.638s
  training loss:		0.001260
Training accuracy:		99.42 %
Final results:
  test loss:			0.002299
  test accuracy:		99.04 %
