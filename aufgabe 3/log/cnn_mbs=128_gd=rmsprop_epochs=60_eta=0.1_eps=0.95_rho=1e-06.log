Loading MNIST dataset...
Creating network...
Using rmsprop for updates with learning rate: 0.1, epsilon: 0.95, rho: 1e-06
Starting training...
Epoch 1 of 60 took 2.087s
  training loss:		0.086992
Epoch 2 of 60 took 2.015s
  training loss:		0.044734
Epoch 3 of 60 took 2.015s
  training loss:		0.027597
Epoch 4 of 60 took 2.016s
  training loss:		0.021182
Epoch 5 of 60 took 2.016s
  training loss:		0.017921
Epoch 6 of 60 took 2.016s
  training loss:		0.015793
Epoch 7 of 60 took 2.020s
  training loss:		0.014269
Epoch 8 of 60 took 2.016s
  training loss:		0.013021
Epoch 9 of 60 took 2.018s
  training loss:		0.012052
Epoch 10 of 60 took 2.018s
  training loss:		0.011245
Epoch 11 of 60 took 2.019s
  training loss:		0.010580
Epoch 12 of 60 took 2.017s
  training loss:		0.010001
Epoch 13 of 60 took 2.019s
  training loss:		0.009498
Epoch 14 of 60 took 2.018s
  training loss:		0.009093
Epoch 15 of 60 took 2.018s
  training loss:		0.008724
Epoch 16 of 60 took 2.018s
  training loss:		0.008387
Epoch 17 of 60 took 2.018s
  training loss:		0.008122
Epoch 18 of 60 took 2.018s
  training loss:		0.007849
Epoch 19 of 60 took 2.019s
  training loss:		0.007635
Epoch 20 of 60 took 2.020s
  training loss:		0.007394
Epoch 21 of 60 took 2.025s
  training loss:		0.007197
Epoch 22 of 60 took 2.026s
  training loss:		0.007021
Epoch 23 of 60 took 2.026s
  training loss:		0.006844
Epoch 24 of 60 took 2.025s
  training loss:		0.006688
Epoch 25 of 60 took 2.026s
  training loss:		0.006537
Epoch 26 of 60 took 2.026s
  training loss:		0.006419
Epoch 27 of 60 took 2.025s
  training loss:		0.006272
Epoch 28 of 60 took 2.026s
  training loss:		0.006145
Epoch 29 of 60 took 2.026s
  training loss:		0.006036
Epoch 30 of 60 took 2.026s
  training loss:		0.005940
Epoch 31 of 60 took 2.025s
  training loss:		0.005812
Epoch 32 of 60 took 2.026s
  training loss:		0.005718
Epoch 33 of 60 took 2.024s
  training loss:		0.005626
Epoch 34 of 60 took 2.027s
  training loss:		0.005534
Epoch 35 of 60 took 2.025s
  training loss:		0.005449
Epoch 36 of 60 took 2.026s
  training loss:		0.005373
Epoch 37 of 60 took 2.028s
  training loss:		0.005283
Epoch 38 of 60 took 2.025s
  training loss:		0.005219
Epoch 39 of 60 took 2.028s
  training loss:		0.005151
Epoch 40 of 60 took 2.028s
  training loss:		0.005049
Epoch 41 of 60 took 2.026s
  training loss:		0.004999
Epoch 42 of 60 took 2.026s
  training loss:		0.004930
Epoch 43 of 60 took 2.028s
  training loss:		0.004874
Epoch 44 of 60 took 2.027s
  training loss:		0.004803
Epoch 45 of 60 took 2.026s
  training loss:		0.004758
Epoch 46 of 60 took 2.027s
  training loss:		0.004687
Epoch 47 of 60 took 2.026s
  training loss:		0.004643
Epoch 48 of 60 took 2.027s
  training loss:		0.004581
Epoch 49 of 60 took 2.026s
  training loss:		0.004541
Epoch 50 of 60 took 2.027s
  training loss:		0.004492
Epoch 51 of 60 took 2.025s
  training loss:		0.004421
Epoch 52 of 60 took 2.026s
  training loss:		0.004374
Epoch 53 of 60 took 2.025s
  training loss:		0.004338
Epoch 54 of 60 took 2.026s
  training loss:		0.004299
Epoch 55 of 60 took 2.026s
  training loss:		0.004250
Epoch 56 of 60 took 2.026s
  training loss:		0.004217
Epoch 57 of 60 took 2.026s
  training loss:		0.004161
Epoch 58 of 60 took 2.025s
  training loss:		0.004141
Epoch 59 of 60 took 2.026s
  training loss:		0.004109
Epoch 60 of 60 took 2.026s
  training loss:		0.004049
Training accuracy:		98.14 %
Final results:
  test loss:			0.003803
  test accuracy:		98.32 %
