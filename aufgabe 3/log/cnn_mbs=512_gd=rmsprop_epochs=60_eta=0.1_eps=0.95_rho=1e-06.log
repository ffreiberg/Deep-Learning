Loading MNIST dataset...
Creating network...
Using rmsprop for updates with learning rate: 0.1, epsilon: 0.95, rho: 1e-06
Starting training...
Epoch 1 of 60 took 1.985s
  training loss:		0.105286
Epoch 2 of 60 took 1.923s
  training loss:		0.085292
Epoch 3 of 60 took 1.924s
  training loss:		0.077867
Epoch 4 of 60 took 1.922s
  training loss:		0.065484
Epoch 5 of 60 took 1.923s
  training loss:		0.052655
Epoch 6 of 60 took 1.921s
  training loss:		0.044011
Epoch 7 of 60 took 1.924s
  training loss:		0.038140
Epoch 8 of 60 took 1.925s
  training loss:		0.033495
Epoch 9 of 60 took 1.926s
  training loss:		0.029874
Epoch 10 of 60 took 1.926s
  training loss:		0.027216
Epoch 11 of 60 took 1.926s
  training loss:		0.025161
Epoch 12 of 60 took 1.924s
  training loss:		0.023527
Epoch 13 of 60 took 1.928s
  training loss:		0.022198
Epoch 14 of 60 took 1.925s
  training loss:		0.021036
Epoch 15 of 60 took 1.926s
  training loss:		0.020052
Epoch 16 of 60 took 1.927s
  training loss:		0.019191
Epoch 17 of 60 took 1.926s
  training loss:		0.018416
Epoch 18 of 60 took 1.926s
  training loss:		0.017694
Epoch 19 of 60 took 1.926s
  training loss:		0.017070
Epoch 20 of 60 took 1.926s
  training loss:		0.016505
Epoch 21 of 60 took 1.926s
  training loss:		0.015981
Epoch 22 of 60 took 1.926s
  training loss:		0.015507
Epoch 23 of 60 took 1.928s
  training loss:		0.015059
Epoch 24 of 60 took 1.926s
  training loss:		0.014640
Epoch 25 of 60 took 1.926s
  training loss:		0.014236
Epoch 26 of 60 took 1.927s
  training loss:		0.013887
Epoch 27 of 60 took 1.926s
  training loss:		0.013544
Epoch 28 of 60 took 1.926s
  training loss:		0.013248
Epoch 29 of 60 took 1.925s
  training loss:		0.012953
Epoch 30 of 60 took 1.925s
  training loss:		0.012651
Epoch 31 of 60 took 1.924s
  training loss:		0.012399
Epoch 32 of 60 took 1.925s
  training loss:		0.012149
Epoch 33 of 60 took 1.925s
  training loss:		0.011902
Epoch 34 of 60 took 1.926s
  training loss:		0.011676
Epoch 35 of 60 took 1.927s
  training loss:		0.011447
Epoch 36 of 60 took 1.990s
  training loss:		0.011251
Epoch 37 of 60 took 1.981s
  training loss:		0.011031
Epoch 38 of 60 took 1.937s
  training loss:		0.010848
Epoch 39 of 60 took 1.929s
  training loss:		0.010662
Epoch 40 of 60 took 1.934s
  training loss:		0.010480
Epoch 41 of 60 took 1.930s
  training loss:		0.010301
Epoch 42 of 60 took 1.931s
  training loss:		0.010149
Epoch 43 of 60 took 1.937s
  training loss:		0.009991
Epoch 44 of 60 took 1.998s
  training loss:		0.009829
Epoch 45 of 60 took 1.936s
  training loss:		0.009690
Epoch 46 of 60 took 1.938s
  training loss:		0.009545
Epoch 47 of 60 took 1.940s
  training loss:		0.009418
Epoch 48 of 60 took 1.936s
  training loss:		0.009285
Epoch 49 of 60 took 1.937s
  training loss:		0.009150
Epoch 50 of 60 took 1.934s
  training loss:		0.009036
Epoch 51 of 60 took 1.934s
  training loss:		0.008916
Epoch 52 of 60 took 1.935s
  training loss:		0.008816
Epoch 53 of 60 took 1.934s
  training loss:		0.008686
Epoch 54 of 60 took 1.937s
  training loss:		0.008595
Epoch 55 of 60 took 1.935s
  training loss:		0.008485
Epoch 56 of 60 took 1.934s
  training loss:		0.008401
Epoch 57 of 60 took 1.939s
  training loss:		0.008310
Epoch 58 of 60 took 1.936s
  training loss:		0.008212
Epoch 59 of 60 took 1.936s
  training loss:		0.008126
Epoch 60 of 60 took 1.935s
  training loss:		0.008050
Training accuracy:		96.21 %
Final results:
  test loss:			0.006999
  test accuracy:		96.80 %
