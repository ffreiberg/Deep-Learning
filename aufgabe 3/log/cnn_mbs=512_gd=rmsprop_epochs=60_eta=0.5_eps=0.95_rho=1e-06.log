Loading MNIST dataset...
Creating network...
Using rmsprop for updates with learning rate: 0.5, epsilon: 0.95, rho: 1e-06
Starting training...
Epoch 1 of 60 took 1.968s
  training loss:		0.084389
Epoch 2 of 60 took 2.001s
  training loss:		0.041999
Epoch 3 of 60 took 2.044s
  training loss:		0.027684
Epoch 4 of 60 took 2.003s
  training loss:		0.020104
Epoch 5 of 60 took 2.015s
  training loss:		0.016264
Epoch 6 of 60 took 2.022s
  training loss:		0.014035
Epoch 7 of 60 took 2.057s
  training loss:		0.012433
Epoch 8 of 60 took 2.017s
  training loss:		0.011351
Epoch 9 of 60 took 1.947s
  training loss:		0.010427
Epoch 10 of 60 took 1.939s
  training loss:		0.009679
Epoch 11 of 60 took 1.952s
  training loss:		0.009088
Epoch 12 of 60 took 1.941s
  training loss:		0.008553
Epoch 13 of 60 took 1.924s
  training loss:		0.008164
Epoch 14 of 60 took 1.924s
  training loss:		0.007774
Epoch 15 of 60 took 1.939s
  training loss:		0.007438
Epoch 16 of 60 took 1.947s
  training loss:		0.007172
Epoch 17 of 60 took 1.933s
  training loss:		0.006907
Epoch 18 of 60 took 1.929s
  training loss:		0.006674
Epoch 19 of 60 took 1.991s
  training loss:		0.006478
Epoch 20 of 60 took 2.000s
  training loss:		0.006277
Epoch 21 of 60 took 1.929s
  training loss:		0.006123
Epoch 22 of 60 took 1.925s
  training loss:		0.005953
Epoch 23 of 60 took 1.928s
  training loss:		0.005800
Epoch 24 of 60 took 1.927s
  training loss:		0.005695
Epoch 25 of 60 took 1.926s
  training loss:		0.005555
Epoch 26 of 60 took 1.925s
  training loss:		0.005438
Epoch 27 of 60 took 1.924s
  training loss:		0.005337
Epoch 28 of 60 took 1.963s
  training loss:		0.005236
Epoch 29 of 60 took 1.956s
  training loss:		0.005139
Epoch 30 of 60 took 1.933s
  training loss:		0.005044
Epoch 31 of 60 took 1.927s
  training loss:		0.004946
Epoch 32 of 60 took 1.925s
  training loss:		0.004890
Epoch 33 of 60 took 1.925s
  training loss:		0.004792
Epoch 34 of 60 took 1.925s
  training loss:		0.004748
Epoch 35 of 60 took 1.925s
  training loss:		0.004663
Epoch 36 of 60 took 1.925s
  training loss:		0.004600
Epoch 37 of 60 took 1.925s
  training loss:		0.004543
Epoch 38 of 60 took 1.925s
  training loss:		0.004466
Epoch 39 of 60 took 1.925s
  training loss:		0.004419
Epoch 40 of 60 took 1.924s
  training loss:		0.004347
Epoch 41 of 60 took 1.927s
  training loss:		0.004310
Epoch 42 of 60 took 1.926s
  training loss:		0.004252
Epoch 43 of 60 took 1.926s
  training loss:		0.004196
Epoch 44 of 60 took 1.998s
  training loss:		0.004146
Epoch 45 of 60 took 1.925s
  training loss:		0.004121
Epoch 46 of 60 took 1.926s
  training loss:		0.004049
Epoch 47 of 60 took 1.968s
  training loss:		0.004026
Epoch 48 of 60 took 1.966s
  training loss:		0.003976
Epoch 49 of 60 took 2.024s
  training loss:		0.003939
Epoch 50 of 60 took 1.995s
  training loss:		0.003896
Epoch 51 of 60 took 1.929s
  training loss:		0.003869
Epoch 52 of 60 took 1.940s
  training loss:		0.003815
Epoch 53 of 60 took 1.955s
  training loss:		0.003785
Epoch 54 of 60 took 1.937s
  training loss:		0.003755
Epoch 55 of 60 took 1.932s
  training loss:		0.003732
Epoch 56 of 60 took 1.948s
  training loss:		0.003690
Epoch 57 of 60 took 1.967s
  training loss:		0.003659
Epoch 58 of 60 took 1.986s
  training loss:		0.003641
Epoch 59 of 60 took 1.927s
  training loss:		0.003586
Epoch 60 of 60 took 1.929s
  training loss:		0.003562
Training accuracy:		98.37 %
Final results:
  test loss:			0.003346
  test accuracy:		98.56 %
