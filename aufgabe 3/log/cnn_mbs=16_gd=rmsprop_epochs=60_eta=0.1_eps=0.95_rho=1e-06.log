Loading MNIST dataset...
Creating network...
Using rmsprop for updates with learning rate: 0.1, epsilon: 0.95, rho: 1e-06
Starting training...
Epoch 1 of 60 took 3.619s
  training loss:		0.030074
Epoch 2 of 60 took 3.558s
  training loss:		0.010274
Epoch 3 of 60 took 3.558s
  training loss:		0.007562
Epoch 4 of 60 took 3.559s
  training loss:		0.006334
Epoch 5 of 60 took 3.560s
  training loss:		0.005602
Epoch 6 of 60 took 3.572s
  training loss:		0.005093
Epoch 7 of 60 took 3.572s
  training loss:		0.004674
Epoch 8 of 60 took 3.573s
  training loss:		0.004376
Epoch 9 of 60 took 3.572s
  training loss:		0.004115
Epoch 10 of 60 took 3.576s
  training loss:		0.003890
Epoch 11 of 60 took 3.571s
  training loss:		0.003684
Epoch 12 of 60 took 3.572s
  training loss:		0.003538
Epoch 13 of 60 took 3.572s
  training loss:		0.003363
Epoch 14 of 60 took 3.571s
  training loss:		0.003256
Epoch 15 of 60 took 3.571s
  training loss:		0.003138
Epoch 16 of 60 took 3.572s
  training loss:		0.003031
Epoch 17 of 60 took 3.571s
  training loss:		0.002920
Epoch 18 of 60 took 3.570s
  training loss:		0.002849
Epoch 19 of 60 took 3.571s
  training loss:		0.002775
Epoch 20 of 60 took 3.571s
  training loss:		0.002689
Epoch 21 of 60 took 3.570s
  training loss:		0.002606
Epoch 22 of 60 took 3.571s
  training loss:		0.002540
Epoch 23 of 60 took 3.570s
  training loss:		0.002454
Epoch 24 of 60 took 3.570s
  training loss:		0.002415
Epoch 25 of 60 took 3.570s
  training loss:		0.002363
Epoch 26 of 60 took 3.572s
  training loss:		0.002324
Epoch 27 of 60 took 3.577s
  training loss:		0.002268
Epoch 28 of 60 took 3.572s
  training loss:		0.002193
Epoch 29 of 60 took 3.574s
  training loss:		0.002152
Epoch 30 of 60 took 3.573s
  training loss:		0.002111
Epoch 31 of 60 took 3.574s
  training loss:		0.002075
Epoch 32 of 60 took 3.574s
  training loss:		0.002017
Epoch 33 of 60 took 3.573s
  training loss:		0.001993
Epoch 34 of 60 took 3.575s
  training loss:		0.001958
Epoch 35 of 60 took 3.575s
  training loss:		0.001928
Epoch 36 of 60 took 3.574s
  training loss:		0.001883
Epoch 37 of 60 took 3.573s
  training loss:		0.001844
Epoch 38 of 60 took 3.574s
  training loss:		0.001836
Epoch 39 of 60 took 3.573s
  training loss:		0.001793
Epoch 40 of 60 took 3.574s
  training loss:		0.001754
Epoch 41 of 60 took 3.575s
  training loss:		0.001718
Epoch 42 of 60 took 3.574s
  training loss:		0.001683
Epoch 43 of 60 took 3.574s
  training loss:		0.001669
Epoch 44 of 60 took 3.579s
  training loss:		0.001628
Epoch 45 of 60 took 3.574s
  training loss:		0.001617
Epoch 46 of 60 took 3.575s
  training loss:		0.001578
Epoch 47 of 60 took 3.574s
  training loss:		0.001576
Epoch 48 of 60 took 3.573s
  training loss:		0.001538
Epoch 49 of 60 took 3.574s
  training loss:		0.001524
Epoch 50 of 60 took 3.575s
  training loss:		0.001499
Epoch 51 of 60 took 3.573s
  training loss:		0.001463
Epoch 52 of 60 took 3.573s
  training loss:		0.001449
Epoch 53 of 60 took 3.573s
  training loss:		0.001408
Epoch 54 of 60 took 3.573s
  training loss:		0.001403
Epoch 55 of 60 took 3.573s
  training loss:		0.001385
Epoch 56 of 60 took 3.576s
  training loss:		0.001360
Epoch 57 of 60 took 3.578s
  training loss:		0.001329
Epoch 58 of 60 took 3.575s
  training loss:		0.001318
Epoch 59 of 60 took 3.574s
  training loss:		0.001290
Epoch 60 of 60 took 3.578s
  training loss:		0.001289
Training accuracy:		99.40 %
Final results:
  test loss:			0.002448
  test accuracy:		98.93 %
